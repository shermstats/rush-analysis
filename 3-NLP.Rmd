---
title: "Text Analysis"
author: "Brandon Sherman"
date: "July 2018"
output: html_document
---

Now that we've analyzed Rush's musical development, what about lyrics?  Most 
natural language processing techniques exist for the analysis of documents, 
articles, or websites.  A song is a considerably smaller piece of text than 
a typical Wikipedia article, and has different textual properties, such as 
heavy repetition as an artistic device.  As a result this analysis is going to 
be fairly rusty, but it'll still be interesting.


One thing that's convenient about analyzing Rush lyrics is that a single author - Neil
Peart - has been Rush's sole lyricist since 1975. For this reason I'll be excluding 
Rush's debut, along with Best I Can and In the End from Fly By Night, as Neil Peart 
did not write any of the lyrics.

I'll also exclude [instrumental songs](https://en.wikipedia.org/wiki/List_of_Rush_instrumentals).  Although 
they're fun to hum along to, their lack of lyrics mean that they sadly will not be part of this analysis.


```{r prep}
library(dplyr)
library(readr)
library(ggplot2)
library(ggforce)
library(patchwork)
library(here)
library(stringr)
library(tidyr)
library(glue)
library(extrafont)
library(forcats)
library(tidytext)
library(purrr)

source(here("lib", "vars.R"))

rush_albums <- readRDS(RUSH_ALBUMS)

instrumental_songs <- c("la villa strangiato", "yyz", "where's my thing?", "leave that thing alone", "limbo",
                        "the main monkey business", "hope", "malignant narcissism")

rush_albums_for_lyrics <- rush_albums %>% 
    filter(album_name != "Rush",  ## Exclude all lyrics not written by Neil Peart
           (!(track_name %in% c("Best I Can", "In The End")))) %>%
    filter(!(tolower(track_name) %in% instrumental_songs)) %>%
    select(album_name, track_n, track_name, lyrics)
```

One big issue here is that the lyrics for each track are in a tibble,
when they should be in one giant string.  Let's fix that.  There is also 
punctuation and capitalization to remove, but the `unnest_tokens` function 
will handle that automatically.

I debated whether to drop repeated lines, but decided against it.  While repeated lines will undoubtedly 
influence counts and frequencies, this is acceptable because repeated lines are clearly important in the 
context of a song.  We will see later on that this was a bad idea and will fix it.

```{r get_lyrics}
lyrics_dat <- rush_albums_for_lyrics %>%
    mutate(lyrics = map(.$lyrics, as.data.frame)) %>%  ## unnest gets annoyed if you give it a tibble instead of a data.frame
    unnest()

lyrics_dat
```

This is convenient.  Lyrics are split into lines, which are already ordered.  This will make 
analyzing small pieces of text straightforward.  But what about if we want to look at lyrics for 
an entire track, or even an entire album?  Let's make data frames to handle that.

```{r}
track_lyrics_dat <- lyrics_dat %>%
  group_by(album_name, track_n, track_name) %>%
  summarize(lyric = paste(lyric, collapse = " ")) %>%
  ungroup()

album_lyrics_dat <- track_lyrics_dat %>%
  group_by(album_name) %>%
  summarize(lyric = paste(lyric, collapse = " ")) %>%
  ungroup()
```

## Word Importance

For each album, what words are most "important"?  We will analyze importance via *tf-idf*.  *tf-idf* is 
the product of two metrics: *term frequency* (tf), which is the number of times a term appears in a 
document, and the *inverse document frequency* (idf), which is equal to $\ln(n_{doc} / n_{doc~with~term})$ 
(thanks again David and Julia!).  The idea is that words that are more common in a given document and also 
less common in other documents must be important.  The `bind_tf_idf` function from the `tidytext` package 
automatically appends `tf-idf` to a data frame of tokens.

What are tokens?  A *token* is a unit of language.  The process of *tokenization* 
is essentially a science and is considerably more difficult than saying "space means new word".  
I'll tokenize Rush lyrics using the `unnest_tokens` function in the `tidytext` package.

Normally we'd replace *stop words*, which are common words like "the" and "which" without much semantic
meaning.  But since we're looking at `tf-idf`, and those words are likely to be in all 
documents, doing so would be redundant.

Normally I would also do some *stemming*, which is the process of getting a word to its base state (e.g. 
dogs -> dog).  But R's existing tools for stemming leave a lot to be desired.  For example, the 
`SnowballC` tokenizer thinks that "everything" is a verb ending in "-ing" and represents it as "everyth".

```{r}
## Order albums by release date, not alphabetically.
##
## see p. 32 of "Text Mining With R"

order_rush_albums <- function(dat) {
  ## Helper function that orders Rush albums in order of 
  ## release date.  Makes for displays that are ordered
  ## chronologically.
  
  album_num <- rush_albums %>%
    filter(album_name != "Rush") %>% 
    select(album_name, album_release_date) %>%
    distinct() %>%
    arrange(album_release_date) %>%
    mutate(album_num = row_number()) %>%
    select(-album_release_date)
  
  dat %>%
    inner_join(album_num, by = "album_name") %>%
    mutate(album_name = fct_reorder(album_name, album_num)) %>%
    select(-album_num)
}

album_words <- album_lyrics_dat %>%
  unnest_tokens(word, lyric, strip_punct = TRUE) %>%
  count(album_name, word, sort = TRUE) %>%
  ungroup()

total_words <- album_words %>%
  group_by(album_name) %>%
  summarize(total = sum(n))

album_words <- album_words %>%
  left_join(total_words, by = "album_name") %>%
  bind_tf_idf(word, album_name, n) %>%
  order_rush_albums()

## Thanks to
## https://drsimonj.svbtle.com/ordering-categories-within-ggplot2-facets
## for how to order bars within facets
reordered_top_tf_idf <- album_words %>%
  group_by(album_name) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  arrange(album_name, tf_idf) %>%
  mutate(order = row_number())

ggplot(reordered_top_tf_idf, aes(x = order, y = tf_idf)) +
  geom_col(aes(color = album_name, fill = album_name), show.legend = FALSE) +
  facet_wrap(~ album_name, scales = "free_y") +
  ggtitle("tf-idf of Rush lyrics by album") +
  xlab("Word") +
  ylab("tf-idf") +
  scale_x_continuous(breaks = reordered_top_tf_idf$order, 
                     labels = reordered_top_tf_idf$word, 
                     expand = c(0, 0)) +
  coord_flip()
```

This is interesting!  Remember that `tf-idf` roughly tells us "what words are most important within each album" by 
comparing occurrence within an album to occurrence outside that album.  So a word that appears a lot in "Fly by Night" 
and very little in "Roll the Bones" would have high `tf-idf` within Fly by Night.

Below are the Top 10 highest `tf-idf` words per album.  Note that many of these have more than ten words due to 
ties.

Some initial findings are:

* Caress of Steel has a lot of fantastic imagery.  Notice the presence of words like "necromancer", "mountain", 
"wraith", "spectres", and "dungeons".  We also see some historical words, like "guillotine" and "bastille", 
which are undoubtedly in "Bastille Day".

* Hemispheres contains a lot of political and Greek mythological imagery.  "Divided", "oppression", "equal", 
and "brothers" appear often.  The top two words, "oaks" and "maples", appear in "The Trees", 
hich is a song about political disputes.  Other words, like "gods", "olympus", and "dionysus" are clearly 
religious.

* Permanent Waves contains a lot of decision-making words and words about doing the right thing, likely due 
to the song "Freewill".  We see "choose", "freewill", and "decide", along with "integrity" and "kindness".  It is an 
album concerned with doing the right thing.

* Vapor Trails contains a lot of lyrics about traveling, likely because it was the first Rush album after 
[Neil Peart's tragic loss of his wife and daughter](https://en.wikipedia.org/wiki/Ghost_Rider:_Travels_on_the_Healing_Road).  Notice the presence of the 
words "earthshine", "rider", "endlessly", and "wilderness".

Some other albums are difficult to classify.  Signals contains a lot of generic words like "he" and "his".  Fly By 
Night contains a bunch of words that do not seem related to each other.  But it's amazing that we can gleam so much 
in a bunch of albums!


## Topic Modeling

Now that we've found some potential topics with nothing but `tf-idf`, let's do a more substantative analysis.  
We'll do this analysis on songs instead of albums, as songs are likely to be more internally consistent than albums.  
We've found some potentially interesting topics by looking at `tf-idf` by eye.  Let's see if a computer 
will find the same topics.  Or better yet, maybe different ones!  This analysis is heavily based on [the topic 
modeling chapter of Tidy Text Mining with R](https://www.tidytextmining.com/topicmodeling.html).

We'll do this with **Latent Dirichlet Allocation** (LDA, which is not to be confused with "linear discriminant 
analysis for the other statisticians out there.")  LDA assumes that every document (album) in your corpus consists 
of some mixture of topics, which can overlap between documents.  The same words can appear in multiple topics.  So 
we have a $word_i \in topic_j \in document_k$ relationship.  The actual math is far more technical than this and 
if you're interested, [it's all in the Wikipedia article](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).

Note that the `topicmodels` package, which contains the most widely used `LDA` function, expects a document-term 
matrix, rather than a tidy dataframe to train a model.  Luckily for us, `tidytext` contains helper functions 
that allow us to go back and forth.

Additionally, because we're going to train an LDA model based on term frequency, we'll drop stop words 
in advance.

```{r}
order_rush_albums_for_tracks <- function(dat) {
  ## Helper function that orders Rush albums in order of 
  ## release date.  Makes for displays that are ordered
  ## chronologically.
  
  album_num <- rush_albums %>%
    filter(album_name != "Rush") %>% 
    select(album_name, album_release_date) %>%
    distinct() %>%
    arrange(album_release_date) %>%
    mutate(album_num = row_number()) %>%
    select(-album_release_date)
  
  dat %>%
    inner_join(album_num) %>%
    mutate(album_name = fct_reorder(album_name, album_num)) %>%
    select(-album_num)
}

track_words <- track_lyrics_dat %>%
  unnest_tokens(word, lyric, strip_punct = TRUE) %>%
  anti_join(stop_words) %>%
  filter(!(word %in% c("heart", "closer", "half", "world"))) %>%  ## words that appear a LOT in a few songs
  count(album_name, track_name, word, sort = TRUE) %>%
  ungroup()

total_track_words <- track_words %>%
  group_by(track_name) %>%
  summarize(total = sum(n))

track_words <- track_words %>%
  left_join(total_track_words, by = "track_name") %>%
  bind_tf_idf(word, track_name, n) %>%
  order_rush_albums_for_tracks
```

```{r}
library(topicmodels)
library(ldatuning)

## song -> tf_idf document-term matrix
track_dtm <- track_words %>%
  anti_join(stop_words) %>%
  select(track_name, word, n) %>%
  cast_dtm(track_name, word, n)

print(track_dtm)

## How many topics?
## https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html

## THIS WILL TAKE A WHILE.
# num_topics <- FindTopicsNumber(album_dtm, 
#                                topics = seq(from = 2, to = 10, by = 1),
#                                metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
#                                method = "VEM",
#                                control = list(seed = 2112),
#                                mc.cores = 4,
#                                verbose = TRUE)

track_lda <- LDA(track_dtm, k = 4, control = list(seed = 2112), method = "Gibbs")

track_lda_topics <- tidy(track_lda, matrix = "beta")
```

We now have four mysterious topics.  What do they represent?

```{r}
track_lda_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta) %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(x = term, y = beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

The topics are:

1.  
